{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Cardiac Myopathy and RNA Therapeutics using DNABERT\n",
    "\n",
    "This notebook demonstrates an end-to-end analysis pipeline that integrates multiple data sources relevant to cardiac myopathy and RNA therapeutics. We will:\n",
    "\n",
    "- Load RNA-seq data from GEO (GSE55296) to examine gene expression differences in heart tissue.\n",
    "- Process GTEx data (RNA-seq TPM, sample attributes, and subject phenotypes) to extract heart-specific expression profiles.\n",
    "- Read in the human reference genome (GRCh38) to enable extraction of nucleotide sequences for target genes.\n",
    "- Outline preliminary steps for using DNABERT_2 for generating DNA embeddings and classifying on-target/off-target siRNA binding sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Set matplotlib style for clarity\n",
    "plt.style.use('default')\n",
    "\n",
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "def get_path(*parts):\n",
    "    \"\"\"Build path relative to notebook location\"\"\"\n",
    "    return os.path.join('..', *parts)\n",
    "\n",
    "print(\"Libraries and configuration loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Directory Structure\n",
    "\n",
    "We assume that the data has been downloaded using the provided `data_download.sh` script, which creates the following directories from the configuration:\n",
    "\n",
    "- GEO directory for RNA-seq series matrix file\n",
    "- ENCODE directory for ChIP-seq data (manual download required)\n",
    "- GTEx directory for RNA-seq TPM data and metadata\n",
    "- Reference directory for the human genome\n",
    "\n",
    "Let's confirm these directories exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all data directories\n",
    "for dir_name, dir_path in config['directories'].items():\n",
    "    full_path = get_path(dir_path)\n",
    "    print(f\"{dir_path}:\", os.listdir(full_path) if os.path.exists(full_path) else \"Directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GEO series matrix file\n",
    "geo_file = get_path(config['directories']['geo'], config['files']['geo']['series_matrix']['filename'])\n",
    "\n",
    "with open(geo_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(\"First 20 lines of GEO series matrix:\")\n",
    "for line in lines[:20]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GTEx data\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "gtex_dir = config['directories']['gtex']\n",
    "\n",
    "# Function to count lines in a file\n",
    "def count_lines(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return sum(1 for _ in f)\n",
    "\n",
    "# Load TPM data with progress bar\n",
    "print(\"Loading GTEx TPM Data...\")\n",
    "gtex_tpm_file = get_path(gtex_dir, config['files']['gtex']['tpm_data']['filename'])\n",
    "total_lines = count_lines(gtex_tpm_file)\n",
    "gtex_df = pd.read_csv(\n",
    "    gtex_tpm_file, \n",
    "    sep='\\t', \n",
    "    skiprows=2,\n",
    "    chunksize=1000,  # Process in chunks to show progress\n",
    ")\n",
    "chunks = []\n",
    "with tqdm(total=total_lines, desc=\"Reading TPM Data\") as pbar:\n",
    "    for chunk in gtex_df:\n",
    "        chunks.append(chunk)\n",
    "        pbar.update(len(chunk))\n",
    "gtex_df = pd.concat(chunks)\n",
    "print(\"GTEx TPM Data shape:\", gtex_df.shape)\n",
    "print(gtex_df.head())\n",
    "\n",
    "# Load sample attributes with progress bar\n",
    "print(\"\\nLoading Sample Attributes...\")\n",
    "sample_attr_file = get_path(gtex_dir, config['files']['gtex']['sample_attributes']['filename'])\n",
    "total_lines = count_lines(sample_attr_file)\n",
    "with tqdm(total=total_lines, desc=\"Reading Sample Attributes\") as pbar:\n",
    "    sample_attr_df = pd.read_csv(\n",
    "        sample_attr_file, \n",
    "        sep='\\t',\n",
    "        chunksize=1000,\n",
    "    )\n",
    "    chunks = []\n",
    "    for chunk in sample_attr_df:\n",
    "        chunks.append(chunk)\n",
    "        pbar.update(len(chunk))\n",
    "sample_attr_df = pd.concat(chunks)\n",
    "print(\"Sample Attributes shape:\", sample_attr_df.shape)\n",
    "print(sample_attr_df.head())\n",
    "\n",
    "# Load subject phenotypes with progress bar\n",
    "print(\"\\nLoading Subject Phenotypes...\")\n",
    "subject_phen_file = get_path(gtex_dir, config['files']['gtex']['subject_phenotypes']['filename'])\n",
    "total_lines = count_lines(subject_phen_file)\n",
    "with tqdm(total=total_lines, desc=\"Reading Subject Phenotypes\") as pbar:\n",
    "    subject_phen_df = pd.read_csv(\n",
    "        subject_phen_file, \n",
    "        sep='\\t',\n",
    "        chunksize=1000,\n",
    "    )\n",
    "    chunks = []\n",
    "    for chunk in subject_phen_df:\n",
    "        chunks.append(chunk)\n",
    "        pbar.update(len(chunk))\n",
    "subject_phen_df = pd.concat(chunks)\n",
    "print(\"Subject Phenotypes shape:\", subject_phen_df.shape)\n",
    "print(subject_phen_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference genome\n",
    "import gzip\n",
    "ref_genome_file = get_path(config['directories']['reference'],\n",
    "                          config['files']['reference']['genome']['filename'])\n",
    "\n",
    "print(\"Reading reference genome (this may take a moment)...\")\n",
    "with gzip.open(ref_genome_file, 'rt') as handle:  # 'rt' mode for text reading\n",
    "    genome_records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "print(f\"Number of sequences in the reference genome: {len(genome_records)}\")\n",
    "print(\"First record:\", genome_records[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DNABERT model\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"zhihan1996/DNABERT-2-117M\"\n",
    "\n",
    "print(\"Loading DNABERT_2 tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "print(\"DNABERT_2 model loaded successfully.\")\n",
    "\n",
    "# Example tokenization\n",
    "sequence = \"ATGCGTACGTAGCTAGCTAGCTAG\"\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(\"Tokenized sequence:\", tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
