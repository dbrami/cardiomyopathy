{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Cardiac Myopathy and RNA Therapeutics using DNABERT\n",
    "\n",
    "This notebook demonstrates an end-to-end analysis pipeline that integrates multiple data sources relevant to cardiac myopathy and RNA therapeutics. We will:\n",
    "\n",
    "- Load RNA-seq data from GEO (GSE55296) to examine gene expression differences in heart tissue.\n",
    "- Process GTEx data (RNA-seq TPM, sample attributes, and subject phenotypes) to extract heart-specific expression profiles.\n",
    "- Read in the human reference genome (GRCh38) to enable extraction of nucleotide sequences for target genes.\n",
    "- Outline preliminary steps for using DNABERT_2 for generating DNA embeddings and classifying on-target/off-target siRNA binding sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Set matplotlib style for clarity\n",
    "plt.style.use('default')\n",
    "\n",
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "def get_path(*parts):\n",
    "    \"\"\"Build path relative to notebook location\"\"\"\n",
    "    return os.path.join('..', *parts)\n",
    "\n",
    "print(\"Libraries and configuration loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Directory Structure\n",
    "\n",
    "We assume that the data has been downloaded using the provided `data_download.sh` script, which creates the following directories from the configuration:\n",
    "\n",
    "- GEO directory for RNA-seq series matrix file\n",
    "- ENCODE directory for ChIP-seq data (manual download required)\n",
    "- GTEx directory for RNA-seq TPM data and metadata\n",
    "- Reference directory for the human genome\n",
    "\n",
    "Let's confirm these directories exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all data directories\n",
    "for dir_name, dir_path in config['directories'].items():\n",
    "    full_path = get_path(dir_path)\n",
    "    print(f\"{dir_path}:\", os.listdir(full_path) if os.path.exists(full_path) else \"Directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GEO series matrix file\n",
    "geo_file = get_path(config['directories']['geo'], config['files']['geo']['series_matrix']['filename'])\n",
    "\n",
    "with open(geo_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(\"First 20 lines of GEO series matrix:\")\n",
    "for line in lines[:20]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GTEx data\n",
    "gtex_dir = config['directories']['gtex']\n",
    "\n",
    "# Load TPM data\n",
    "gtex_tpm_file = get_path(gtex_dir, config['files']['gtex']['tpm_data']['filename'])\n",
    "gtex_df = pd.read_csv(gtex_tpm_file, sep='\\t', skiprows=2)\n",
    "print(\"GTEx TPM Data shape:\", gtex_df.shape)\n",
    "print(gtex_df.head())\n",
    "\n",
    "# Load sample attributes\n",
    "sample_attr_file = get_path(gtex_dir, config['files']['gtex']['sample_attributes']['filename'])\n",
    "sample_attr_df = pd.read_csv(sample_attr_file, sep='\\t')\n",
    "print(\"\\nSample Attributes shape:\", sample_attr_df.shape)\n",
    "print(sample_attr_df.head())\n",
    "\n",
    "# Load subject phenotypes\n",
    "subject_phen_file = get_path(gtex_dir, config['files']['gtex']['subject_phenotypes']['filename'])\n",
    "subject_phen_df = pd.read_csv(subject_phen_file, sep='\\t')\n",
    "print(\"\\nSubject Phenotypes shape:\", subject_phen_df.shape)\n",
    "print(subject_phen_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference genome\n",
    "ref_genome_file = get_path(config['directories']['reference'],\n",
    "                          config['files']['reference']['genome']['filename'])\n",
    "\n",
    "print(\"Reading reference genome (this may take a moment)...\")\n",
    "genome_records = list(SeqIO.parse(ref_genome_file, \"fasta\"))\n",
    "print(f\"Number of sequences in the reference genome: {len(genome_records)}\")\n",
    "print(\"First record:\", genome_records[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DNABERT model\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "model_path = '../src/DNABERT_2'\n",
    "\n",
    "print(\"Loading DNABERT_2 tokenizer and model...\")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, do_lower_case=False)\n",
    "model = BertModel.from_pretrained(model_path)\n",
    "\n",
    "print(\"DNABERT_2 model loaded successfully.\")\n",
    "\n",
    "# Example tokenization\n",
    "sequence = \"ATGCGTACGTAGCTAGCTAGCTAG\"\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(\"Tokenized sequence:\", tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
